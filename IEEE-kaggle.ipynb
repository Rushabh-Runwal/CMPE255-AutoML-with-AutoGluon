{"cells":[{"cell_type":"markdown","id":"0fa7eb3d","metadata":{"id":"0fa7eb3d"},"source":["# How to use AutoGluon for Kaggle competitions\n","\n"]},{"cell_type":"code","source":["# !pip install kaggle"],"metadata":{"id":"gI2PnPCSIA4D","executionInfo":{"status":"ok","timestamp":1727399221403,"user_tz":420,"elapsed":252,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}},"collapsed":true},"id":"gI2PnPCSIA4D","execution_count":1,"outputs":[]},{"cell_type":"code","source":["!gdown 1seOAJxGY0MxdR90-emKqGFY0ejUcp8tn\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4cXdFtWTINu","executionInfo":{"status":"ok","timestamp":1727399227635,"user_tz":420,"elapsed":5467,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}},"outputId":"c5c24b1d-c854-4721-da2d-ee03836e5e86"},"id":"H4cXdFtWTINu","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1seOAJxGY0MxdR90-emKqGFY0ejUcp8tn\n","To: /content/kaggle.json\n","\r  0% 0.00/69.0 [00:00<?, ?B/s]\r100% 69.0/69.0 [00:00<00:00, 393kB/s]\n"]}]},{"cell_type":"code","source":["!kaggle competitions download -c ieee-fraud-detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZ2pDKVaIzk2","executionInfo":{"status":"ok","timestamp":1727399231081,"user_tz":420,"elapsed":3448,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}},"outputId":"a0be2c64-3698-45c9-8b4a-20ef4ec5160a"},"id":"UZ2pDKVaIzk2","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading ieee-fraud-detection.zip to /content\n"," 97% 115M/118M [00:01<00:00, 80.8MB/s]\n","100% 118M/118M [00:01<00:00, 66.3MB/s]\n"]}]},{"cell_type":"code","source":["!unzip ieee-fraud-detection.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26r1m023JNmE","executionInfo":{"status":"ok","timestamp":1727399243260,"user_tz":420,"elapsed":12181,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}},"outputId":"d86fbbe8-501b-48d3-b9ea-d22eccc85844","collapsed":true},"id":"26r1m023JNmE","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  ieee-fraud-detection.zip\n","  inflating: sample_submission.csv   \n","  inflating: test_identity.csv       \n","  inflating: test_transaction.csv    \n","  inflating: train_identity.csv      \n","  inflating: train_transaction.csv   \n"]}]},{"cell_type":"code","source":["!python -m pip install --upgrade pip --quiet\n","!python -m pip install autogluon.tabular[all] --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4jwU_6TJW9u","executionInfo":{"status":"ok","timestamp":1727399588421,"user_tz":420,"elapsed":27660,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}},"outputId":"cf6bd342-8f9a-402d-9517-a957c0718571","collapsed":true},"id":"e4jwU_6TJW9u","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install --upgrade pyarrow --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAj13zo7OfsO","executionInfo":{"status":"ok","timestamp":1727399603391,"user_tz":420,"elapsed":8282,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}},"outputId":"9548346b-9075-4e14-c9dc-edcd67a80faa"},"id":"AAj13zo7OfsO","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from autogluon.tabular import TabularPredictor\n","\n","directory = '/content/' # directory where you have downloaded the data CSV files from the competition\n","label = 'isFraud'  # name of target variable to predict in this competition\n","eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n","save_path = directory + 'AutoGluonModels/'  # where to store trained models\n","\n","train_identity = pd.read_csv(directory+'train_identity.csv')\n","train_transaction = pd.read_csv(directory+'train_transaction.csv')"],"metadata":{"id":"4h8Aa1ZeG61N","executionInfo":{"status":"ok","timestamp":1727399641863,"user_tz":420,"elapsed":38475,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}}},"id":"4h8Aa1ZeG61N","execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"],"metadata":{"id":"UMfUmtT_KMvv","executionInfo":{"status":"ok","timestamp":1727399643913,"user_tz":420,"elapsed":2053,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}}},"id":"UMfUmtT_KMvv","execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Refactor with a focus on resource efficiency\n","predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=2).fit(\n","    train_data, presets='best_quality', time_limit=60, ag_args_fit={'num_gpus': 0, 'num_cpus': 2}, excluded_model_types=['KNN', 'XT']\n",")\n","\n","results = predictor.fit_summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NbDbFq39KN_W","executionInfo":{"status":"error","timestamp":1727399671898,"user_tz":420,"elapsed":27988,"user":{"displayName":"Rushabh Gautam Runwal","userId":"11531149364159956895"}},"outputId":"688b36a6-d8c5-4978-fe6c-7fb7328e0921"},"id":"NbDbFq39KN_W","execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.1.1\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n","CPU Count:          2\n","Memory Avail:       6.28 GB / 12.67 GB (49.6%)\n","Disk Space Avail:   61.61 GB / 112.64 GB (54.7%)\n","===================================================\n","Presets specified: ['best_quality']\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 15s of the 60s of remaining time (25%).\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n","2024-09-27 01:14:12,174\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n","\t\tContext path: \"/content/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.28.0.12, ID: eceb84e7e9f5bc047eec5c950f38a65749a2b918d77f931dcad270aa) where the task (task ID: 1dd1256c3118aa82ba685170bc65a77f3b05f41701000000, name=_dystack, pid=2490, memory used=3.31GB) was running was 12.08GB / 12.67GB (0.953373), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: cfbf731d287a7c822cbacfae159a2c98b000324754f227502664c443) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-cfbf731d287a7c822cbacfae159a2c98b000324754f227502664c443*out -ip 172.28.0.12. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n289\t5.32\t/usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter/runtime/kernel-e79207da-c0e9...\n2490\t3.31\tray::_dystack\n2318\t0.29\tnode /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:a707f1a3f72f70b10...\n119\t0.11\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n2472\t0.07\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n2380\t0.06\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n2375\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n2456\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --session-di...\n2474\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/runtime_env/agent/main.py -...\n2342\t0.04\t/usr/local/lib/python3.10/dist-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/session_2...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-b3246623ca9b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Refactor with a focus on resource efficiency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=2).fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best_quality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_args_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'num_gpus'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_cpus'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexcluded_model_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'XT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0;34m\"AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m             )\n\u001b[0;32m-> 1151\u001b[0;31m             \u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_stacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mds_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m             logger.info(\n\u001b[1;32m   1153\u001b[0m                 \u001b[0;34mf\"Starting main fit with num_stack_levels={num_stack_levels}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_dynamic_stacking\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs, validation_procedure, detection_time_frac, holdout_frac, n_folds, n_repeats, memory_safe_fits, clean_up_fits, enable_ray_logging, holdout_data)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                 \u001b[0mds_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ds_fit_context\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_fit_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sub_fit_custom_ho\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m             stacked_overfitting = self._sub_fit_memory_save_wrapper(\n\u001b[0m\u001b[1;32m   1243\u001b[0m                 \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_sub_fit_memory_save_wrapper\u001b[0;34m(self, train_data, time_limit, time_start, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[0m\n\u001b[1;32m   1423\u001b[0m                 )\n\u001b[1;32m   1424\u001b[0m                 \u001b[0mfinished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ds_ray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_returns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m                 \u001b[0mstacked_overfitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mho_leaderboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ds_ray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m                 \u001b[0;31m# TODO: This is present to ensure worker logs are properly logged and don't get skipped / printed out of order.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\u001b[0m in \u001b[0;36mauto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mauto_init_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m         \u001b[0;31m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugger_breakpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    864\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugger_breakpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.28.0.12, ID: eceb84e7e9f5bc047eec5c950f38a65749a2b918d77f931dcad270aa) where the task (task ID: 1dd1256c3118aa82ba685170bc65a77f3b05f41701000000, name=_dystack, pid=2490, memory used=3.31GB) was running was 12.08GB / 12.67GB (0.953373), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: cfbf731d287a7c822cbacfae159a2c98b000324754f227502664c443) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-cfbf731d287a7c822cbacfae159a2c98b000324754f227502664c443*out -ip 172.28.0.12. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n289\t5.32\t/usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter/runtime/kernel-e79207da-c0e9...\n2490\t3.31\tray::_dystack\n2318\t0.29\tnode /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:a707f1a3f72f70b10...\n119\t0.11\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n2472\t0.07\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n2380\t0.06\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n2375\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n2456\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --session-di...\n2474\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/runtime_env/agent/main.py -...\n2342\t0.04\t/usr/local/lib/python3.10/dist-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/session_2...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero."]}]},{"cell_type":"code","source":["test_identity = pd.read_csv(directory+'test_identity.csv')\n","test_transaction = pd.read_csv(directory+'test_transaction.csv')\n","test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n","\n","y_predproba = predictor.predict_proba(test_data)\n","y_predproba.head(5)  # some example predicted fraud-probabilities"],"metadata":{"id":"4bvBk6ZgKPc5"},"id":"4bvBk6ZgKPc5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictor.positive_class"],"metadata":{"id":"-UkMqwRRKQ95"},"id":"-UkMqwRRKQ95","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictor.class_labels  # classes in this list correspond to columns of predict_proba() output"],"metadata":{"id":"FjrDfBLZKSGj"},"id":"FjrDfBLZKSGj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predproba = predictor.predict_proba(test_data, as_multiclass=False)"],"metadata":{"id":"sGR6l_HnKTZr"},"id":"sGR6l_HnKTZr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission = pd.read_csv(directory+'sample_submission.csv')\n","submission['isFraud'] = y_predproba\n","submission.head()\n","submission.to_csv(directory+'my_submission.csv', index=False)"],"metadata":{"id":"24ZnJ316KUot"},"id":"24ZnJ316KUot","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"https://github.com/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb","timestamp":1726005582280}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}